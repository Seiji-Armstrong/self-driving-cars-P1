{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "\n",
    "\n",
    "### Pipeline Description\n",
    "\n",
    "My approach was to first get a pipeline working that included the helper functions, but didn't really do anything useful. Then I would explore the outputs of each one, and iteratively place the helpers in a sequence that made logical sense. For example first I was doing region selection, then some processing, then another round of region selection. Without fine tuning the first few steps I realised I could just include one call of the region selection, right before the Hough transformations.\n",
    "\n",
    "Only after I was happy with the order of helper functions, and I was confident I knew enough about how each one behaved, did I start tweaking the parameters and including short functions of my own. Here, I had a lot of ideas, but just worked on ones that sounded fun and would be easy to code and efficient.\n",
    "\n",
    "My final pipeline consists of the following steps:\n",
    "\n",
    "#### Grayscale\n",
    "Convert image to grayscale, in order to reduce the dimensionality of the space from 3 (RGB) to 1. The single dimension becomes intensity.\n",
    "\n",
    "#### Gaussian Blur\n",
    "Apply a Gaussian blur as a low-pass filter in spatial frequencies.\n",
    "\n",
    "#### Canny Edge Detection\n",
    "Find spatial regions of highest derivative, which are indicative of lane lines, and edges in general.\n",
    "\n",
    "#### Select Region of Interest\n",
    "As the camera is mounted at a fixed position, and the positions of lane lines are fairly predictable, we are only interested in certain regions of the frame. Create a polygon mask and set ouside frame to black.\n",
    "\n",
    "#### Hough Transformations\n",
    "Apply a transformation of the parameter space and look at polar coordinates to see which lines are relevant from Canny Edge detection, and produce clusters of line segments.\n",
    "\n",
    "#### Draw Lines\n",
    "\n",
    "Take the line segments from the Hough Transformations and produe two final lane lines (left and right) by interpolating and using a linear fit through sensible points.\n",
    "\n",
    "### Potential shortcomings with pipeline\n",
    "\n",
    "If there were markings on the road, within the lane lines, my pipeline could be fooled. If for example this was shown some Chinese or Japanese roads, where their writing has a lot of straight lines, and at different angles, my algo could potentially see some as lane lines. These writings are often in the same colour as the lane lines, so this could trip my pipeline. My algo would also fail when changing lanes... whoops! Hard coding in the region of interest might not be the best idea for a generalised algo. Works here though.. gotta solve one thing at a time...\n",
    "\n",
    "\n",
    "### Possible improvements to pipeline\n",
    "\n",
    "One cool idea would be to automatically pull out the vertices for the region of interest mask. I could do this by crudely detecting lines (cheaply, even with noise), and then draw a fairly tight polygon around it (like a triangle with a flat top). I imagined I would run into problems so I didn't explore this idea.\n",
    "\n",
    "\n",
    "### Reflections\n",
    "\n",
    "The first video didn't give me much trouble, but I spent a bit of time on the next one! I occasionally had lines that would flash in between scenes that were nonsensical. I tried many, many different things and in the end I had what almost amounts to a self-inflicted bug. I was using the mid-points of each line returned from the Hough transformations to feed into the np.polyfit algo, which of course has the potential to bug out as canny edge detection produces two lines per lane line, as there are two edges of the thick line. So this becomes reduced to two points separated horizontally, when I use the midpoints, also losing the length information of the lane line. Foolish. As a result though, I trouble shooted every line of code, and really understood what every helper function was doing... so kinda useful...\n",
    "\n",
    "Another thought: how was I evaluating this? By eye. I was simply applying the different functions either one-by-one or by multiples, and eye-balling the outputs. While this is good for building intuition, it is very slow. And only qualititative. I don't have any quantitative metrics that I created so it is difficult to optimise after a certain point. Given the project specs, and the short timeline, this is acceptable, but if I was doing this for work, or for a real project I would get quantitative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
